{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2175492,"sourceType":"datasetVersion","datasetId":1305990,"isSourceIdPinned":false},{"sourceId":14504424,"sourceType":"datasetVersion","datasetId":9263915}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!rm -rf /kaggle/working/*","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-05T05:15:32.017878Z","iopub.execute_input":"2026-02-05T05:15:32.018310Z","iopub.status.idle":"2026-02-05T05:15:32.143254Z","shell.execute_reply.started":"2026-02-05T05:15:32.018273Z","shell.execute_reply":"2026-02-05T05:15:32.141982Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!git clone https://github.com/EfficientTraining/LabelBench.git","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -r /kaggle/working/LabelBench/requirements.txt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import kagglehub\n\npath = kagglehub.dataset_download(\"cyizhuo/cub-200-2011-by-classes-folder\")\nprint(path)\n\n!mkdir -p ./data\n!cp -r /kaggle/input/cub-200-2011-by-classes-folder ./data/","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir -p ./data/notmnist\n!cp -r /kaggle/input/notmnist/notMNIST_small ../data/notmnist/\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working/LabelBench\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T05:17:35.258538Z","iopub.execute_input":"2026-02-05T05:17:35.258933Z","iopub.status.idle":"2026-02-05T05:17:35.266214Z","shell.execute_reply.started":"2026-02-05T05:17:35.258900Z","shell.execute_reply":"2026-02-05T05:17:35.265212Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/LabelBench\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T05:17:35.267344Z","iopub.execute_input":"2026-02-05T05:17:35.267699Z","iopub.status.idle":"2026-02-05T05:17:35.408038Z","shell.execute_reply.started":"2026-02-05T05:17:35.267671Z","shell.execute_reply":"2026-02-05T05:17:35.406694Z"}},"outputs":[{"name":"stdout","text":"\u001b[0m\u001b[01;34mconfigs\u001b[0m/        \u001b[01;34mLabelBench\u001b[0m/  mp_eval_launcher.py  README.md\n\u001b[01;34mdocs\u001b[0m/           LICENSE      mp_launcher.py       requirements.txt\nexample_run.sh  main.py      point_evaluation.py  \u001b[01;34mresults\u001b[0m/\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### TINYIMAGENET","metadata":{}},{"cell_type":"code","source":"!cat << 'EOF' > LabelBench/dataset/dataset_impl/tinyimagenet_dataset.py\nimport os\nimport zipfile\nimport urllib.request\nimport shutil\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom LabelBench.skeleton.dataset_skeleton import register_dataset, LabelType, TransformDataset\nimport torch\nimport torch.nn.functional as F\n\n\nURL = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n\ndef one_hot_target(y):\n    return F.one_hot(torch.tensor(y), num_classes=200).float()\n\n\ndef is_image_file(path):\n    return path.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n\n\ndef download_and_prepare(data_dir):\n    root = os.path.join(data_dir, \"tiny-imagenet-200\")\n    zip_path = os.path.join(data_dir, \"tiny-imagenet-200.zip\")\n\n    if os.path.exists(root):\n        return root\n\n    os.makedirs(data_dir, exist_ok=True)\n\n    print(\"Downloading TinyImageNet...\")\n    urllib.request.urlretrieve(URL, zip_path)\n\n    print(\"Extracting TinyImageNet...\")\n    with zipfile.ZipFile(zip_path, \"r\") as z:\n        z.extractall(data_dir)\n\n    # -------- FIX TRAIN --------\n    print(\"Fixing train folder structure...\")\n    train_dir = os.path.join(root, \"train\")\n    for cls in os.listdir(train_dir):\n        cls_path = os.path.join(train_dir, cls)\n        images_dir = os.path.join(cls_path, \"images\")\n        if os.path.isdir(images_dir):\n            for img in os.listdir(images_dir):\n                shutil.move(\n                    os.path.join(images_dir, img),\n                    os.path.join(cls_path, img),\n                )\n            shutil.rmtree(images_dir)\n\n    # -------- FIX VAL --------\n    print(\"Fixing val folder structure...\")\n    val_dir = os.path.join(root, \"val\")\n    img_dir = os.path.join(val_dir, \"images\")\n    ann_file = os.path.join(val_dir, \"val_annotations.txt\")\n\n    with open(ann_file, \"r\") as f:\n        annotations = [line.strip().split(\"\\t\") for line in f]\n\n    for img, cls, *_ in annotations:\n        cls_dir = os.path.join(val_dir, cls)\n        os.makedirs(cls_dir, exist_ok=True)\n        shutil.move(os.path.join(img_dir, img), os.path.join(cls_dir, img))\n\n    shutil.rmtree(img_dir)\n    os.remove(ann_file)\n\n    print(\"TinyImageNet ready at:\", root)\n    return root\n\n\n@register_dataset(\"tinyimagenet\", LabelType.MULTI_CLASS)\ndef get_tinyimagenet_dataset(data_dir, *args):\n    root = download_and_prepare(data_dir)\n\n    train_tf = transforms.Compose([\n        transforms.RandomResizedCrop(64),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n    ])\n\n    test_tf = transforms.Compose([\n        transforms.Resize(64),\n        transforms.CenterCrop(64),\n        transforms.ToTensor(),\n    ])\n\n    train_ds = ImageFolder(os.path.join(root, \"train\"))\n    val_ds = ImageFolder(os.path.join(root, \"val\"))\n\n    return (\n        TransformDataset(train_ds,transform=train_tf,target_transform=one_hot_target),\n        TransformDataset(val_ds, transform=test_tf),\n        TransformDataset(val_ds, transform=test_tf),\n        None, None, None,\n        200,\n        train_ds.classes\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T05:17:35.410281Z","iopub.execute_input":"2026-02-05T05:17:35.410779Z","iopub.status.idle":"2026-02-05T05:17:44.839649Z","shell.execute_reply.started":"2026-02-05T05:17:35.410729Z","shell.execute_reply":"2026-02-05T05:17:44.838556Z"}},"outputs":[{"name":"stdout","text":"/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `EOF')\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"### CUB200","metadata":{}},{"cell_type":"code","source":"!cat << 'EOF' > LabelBench/dataset/dataset_impl/cub200_dataset.py\nimport os\nimport torch\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom LabelBench.skeleton.dataset_skeleton import register_dataset, LabelType, TransformDataset\nNUM_CLASSES = 200\n\ndef one_hot_target(y):\n    return F.one_hot(torch.tensor(y), num_classes=NUM_CLASSES).float()\n\n@register_dataset(\"cub200\", LabelType.MULTI_CLASS)\ndef get_cub200_dataset(data_dir, *args):\n    # root = os.path.join(data_dir, \"cub-200-2011-by-classes-folder\")\n    data_dir = os.path.abspath(data_dir)\n    root = os.path.join(data_dir, \"cub-200-2011-by-classes-folder\")\n\n    train_dir = os.path.join(root, \"train\")\n    test_dir  = os.path.join(root, \"test\")\n\n    if not os.path.isdir(train_dir):\n        raise RuntimeError(f\"Train directory not found: {train_dir}\")\n    if not os.path.isdir(test_dir):\n        raise RuntimeError(f\"Test directory not found: {test_dir}\")\n\n    train_tf = transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n    ])\n\n    test_tf = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n    ])\n\n    train_ds = ImageFolder(train_dir)\n    test_ds  = ImageFolder(test_dir)\n\n    return (\n        TransformDataset(train_ds, transform=train_tf, target_transform=one_hot_target),\n        TransformDataset(test_ds,  transform=test_tf,  target_transform=one_hot_target),  # val\n        TransformDataset(test_ds,  transform=test_tf,  target_transform=one_hot_target),  # test\n        None, None, None,\n        NUM_CLASSES,\n        train_ds.classes\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T05:17:44.840915Z","iopub.execute_input":"2026-02-05T05:17:44.841505Z","iopub.status.idle":"2026-02-05T05:17:44.980635Z","shell.execute_reply.started":"2026-02-05T05:17:44.841468Z","shell.execute_reply":"2026-02-05T05:17:44.979490Z"}},"outputs":[{"name":"stdout","text":"/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `EOF')\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### SPLITCIFAR100","metadata":{}},{"cell_type":"code","source":"!cat << 'EOF' > LabelBench/dataset/dataset_impl/splitcifar100_dataset.py\nimport torch\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import Dataset\nfrom LabelBench.skeleton.dataset_skeleton import register_dataset, LabelType, TransformDataset\n\n# CIFAR-100 → 20 tasks, 5 classes each\nSPLITS = {\n    i: list(range(i * 5, (i + 1) * 5))\n    for i in range(20)\n}\n\n\nclass SplitCIFAR100(Dataset):\n    \"\"\"\n    PURE FILTER DATASET\n    - returns (x, y)\n    - NO transforms\n    - NO one-hot\n    \"\"\"\n\n    def __init__(self, base_ds, allowed_classes):\n        self.base_ds = base_ds\n        self.allowed = allowed_classes\n\n        self.indices = [\n            i for i, (_, y) in enumerate(base_ds) if y in allowed_classes\n        ]\n\n        self.class_map = {c: i for i, c in enumerate(allowed_classes)}\n\n    def __len__(self):\n        return len(self.indices)\n\n    def __getitem__(self, idx):\n        x, y = self.base_ds[self.indices[idx]]\n        y = self.class_map[y]\n        return x, y\n\n\ndef one_hot(y, n):\n    return F.one_hot(torch.tensor(y), num_classes=n).float()\n\n\n@register_dataset(\"splitcifar100\", LabelType.MULTI_CLASS)\ndef get_splitcifar100(_):\n    raise RuntimeError(\"Use splitcifar100_<id>, e.g. splitcifar100_0\")\n\n\n# register splitcifar100_0 ... splitcifar100_19\nfor split_id, classes in SPLITS.items():\n\n    @register_dataset(f\"splitcifar100_{split_id}\", LabelType.MULTI_CLASS)\n    def _make_split(data_dir, classes=classes):\n\n        train_tf = transforms.Compose([\n            transforms.RandomCrop(32, padding=4),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n        ])\n\n        test_tf = transforms.Compose([\n            transforms.ToTensor(),\n        ])\n\n        base_train = datasets.CIFAR100(\n            root=data_dir, train=True, download=True\n        )\n        base_test = datasets.CIFAR100(\n            root=data_dir, train=False, download=True\n        )\n\n        train_ds = SplitCIFAR100(base_train, classes)\n        test_ds  = SplitCIFAR100(base_test, classes)\n\n        n_cls = len(classes)  # = 5\n\n        return (\n            TransformDataset(\n                train_ds,\n                transform=train_tf,\n                target_transform=lambda y: one_hot(y, n_cls),\n            ),\n            TransformDataset(\n                test_ds,\n                transform=test_tf,\n                target_transform=lambda y: one_hot(y, n_cls),\n            ),\n            TransformDataset(\n                test_ds,\n                transform=test_tf,\n                target_transform=lambda y: one_hot(y, n_cls),\n            ),\n            None, None, None,\n            n_cls,\n            [str(c) for c in classes],\n        )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T05:17:44.984173Z","iopub.execute_input":"2026-02-05T05:17:44.984504Z","iopub.status.idle":"2026-02-05T05:17:45.131742Z","shell.execute_reply.started":"2026-02-05T05:17:44.984473Z","shell.execute_reply":"2026-02-05T05:17:45.130557Z"}},"outputs":[{"name":"stdout","text":"/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `EOF')\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"### FASHIONMNIST","metadata":{}},{"cell_type":"code","source":"!cat << 'EOF' > LabelBench/dataset/dataset_impl/fashionmnist_dataset.py\nimport torch\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nfrom LabelBench.skeleton.dataset_skeleton import register_dataset, LabelType, TransformDataset\n\ndef one_hot(y, n):\n    return F.one_hot(torch.tensor(y), num_classes=n).float()\n\n@register_dataset(\"fashionmnist\", LabelType.MULTI_CLASS)\ndef get_fashionmnist(data_dir):\n\n    tf = transforms.Compose([\n        transforms.ToTensor(),\n    ])\n\n    train_ds = datasets.FashionMNIST(\n        root=data_dir, train=True, download=True\n    )\n    test_ds = datasets.FashionMNIST(\n        root=data_dir, train=False, download=True\n    )\n\n    n_cls = 10\n\n    return (\n        TransformDataset(train_ds, transform=tf,\n                         target_transform=lambda y: one_hot(y, n_cls)),\n        TransformDataset(test_ds, transform=tf,\n                         target_transform=lambda y: one_hot(y, n_cls)),\n        TransformDataset(test_ds, transform=tf,\n                         target_transform=lambda y: one_hot(y, n_cls)),\n        None, None, None,\n        n_cls,\n        train_ds.classes,\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T05:17:45.133492Z","iopub.execute_input":"2026-02-05T05:17:45.134309Z","iopub.status.idle":"2026-02-05T05:17:45.269378Z","shell.execute_reply.started":"2026-02-05T05:17:45.134264Z","shell.execute_reply":"2026-02-05T05:17:45.268245Z"}},"outputs":[{"name":"stdout","text":"/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `EOF')\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"### NOTMNIST","metadata":{}},{"cell_type":"code","source":"!cat << 'EOF' > LabelBench/dataset/dataset_impl/notmnist_dataset.py\nimport os\nimport torch\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom LabelBench.skeleton.dataset_skeleton import register_dataset, LabelType, TransformDataset\n\n\ndef one_hot(y, n):\n    return F.one_hot(torch.tensor(y), num_classes=n).float()\n\n\n@register_dataset(\"notmnist\", LabelType.MULTI_CLASS)\ndef get_notmnist_dataset(data_dir):\n    \"\"\"\n    Expected structure:\n    data_dir/notmnist/notMNIST_small/\n        A/\n        B/\n        ...\n        J/\n    \"\"\"\n    root = os.path.join(data_dir, \"notmnist\")\n\n    if not os.path.isdir(root):\n        raise RuntimeError(f\"NOTMNIST not found at {root}\")\n\n    train_tf = transforms.Compose([\n        transforms.Grayscale(num_output_channels=1),\n        transforms.Resize((28, 28)),\n        transforms.ToTensor(),\n    ])\n\n    test_tf = transforms.Compose([\n        transforms.Grayscale(num_output_channels=1),\n        transforms.Resize((28, 28)),\n        transforms.ToTensor(),\n    ])\n\n    base_ds = ImageFolder(root)\n    num_classes = len(base_ds.classes)\n\n    return (\n        TransformDataset(\n            base_ds,\n            transform=train_tf,\n            target_transform=lambda y: one_hot(y, num_classes),\n        ),\n        TransformDataset(\n            base_ds,\n            transform=test_tf,\n            target_transform=lambda y: one_hot(y, num_classes),\n        ),\n        TransformDataset(\n            base_ds,\n            transform=test_tf,\n            target_transform=lambda y: one_hot(y, num_classes),\n        ),\n        None, None, None,\n        num_classes,\n        base_ds.classes,\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T05:17:45.270926Z","iopub.execute_input":"2026-02-05T05:17:45.271304Z","iopub.status.idle":"2026-02-05T05:17:45.410631Z","shell.execute_reply.started":"2026-02-05T05:17:45.271269Z","shell.execute_reply":"2026-02-05T05:17:45.409444Z"}},"outputs":[{"name":"stdout","text":"/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `EOF')\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# !echo \"import LabelBench.dataset.dataset_impl.splitcifar10_dataset\" >> LabelBench/dataset/datasets.py\n!echo \"import LabelBench.dataset.dataset_impl.cub200_dataset\" >> LabelBench/dataset/datasets.py\n!echo \"import LabelBench.dataset.dataset_impl.splitcifar100_dataset\" >> LabelBench/dataset/datasets.py\n!echo \"import LabelBench.dataset.dataset_impl.fashionmnist_dataset\" >> LabelBench/dataset/datasets.py\n!echo \"import LabelBench.dataset.dataset_impl.notmnist_dataset\" >> LabelBench/dataset/datasets.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T05:17:45.412306Z","iopub.execute_input":"2026-02-05T05:17:45.413236Z","iopub.status.idle":"2026-02-05T05:17:45.910814Z","shell.execute_reply.started":"2026-02-05T05:17:45.413200Z","shell.execute_reply":"2026-02-05T05:17:45.909314Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"### TEST SCRIPT OF DATALOADER","metadata":{}},{"cell_type":"code","source":"# test_all_datasets.py\n!cat << 'EOF' > test_all_datasets.py\nfrom LabelBench.dataset.datasets import get_dataset\nfrom torch.utils.data import DataLoader\n\n\ndef test_dataset(name, data_dir=\"../data\"):\n    print(\"\\n\" + \"=\" * 50)\n    print(f\"Testing dataset: {name}\")\n    print(\"=\" * 50)\n\n    try:\n        dataset = get_dataset(name, data_dir)\n\n        print(\"ALDataset created ✓\")\n        print(\"Number of classes:\", dataset.get_num_classes())\n\n        train_ds = dataset.train_dataset\n        val_ds   = dataset.val_dataset\n        test_ds  = dataset.test_dataset\n\n        print(\"Train size:\", len(train_ds))\n        print(\"Val size:\", len(val_ds))\n        print(\"Test size:\", len(test_ds))\n\n        # ---- single sample check ----\n        x, y = train_ds[0]\n        print(\"Single image shape:\", x.shape)\n        print(\"Single label shape:\", y.shape)\n\n        # ---- dataloader check ----\n        loader = DataLoader(\n            train_ds,\n            batch_size=8,\n            shuffle=True,\n            num_workers=2\n        )\n        bx, by = next(iter(loader))\n        print(\"Batch image shape:\", bx.shape)\n        print(\"Batch label shape:\", by.shape)\n\n        print(f\"{name} ✅ DATASET + DATALOADER WORKING\")\n\n    except Exception as e:\n        print(f\"{name} ❌ FAILED\")\n        print(\"Reason:\", e)\n\n\n# ==============================\n# Run all dataset checks\n# ==============================\ntest_dataset(\"cifar10\")\ntest_dataset(\"cifar100\")\ntest_dataset(\"tinyimagenet\")\ntest_dataset(\"cub200\")\ntest_dataset(\"fashionmnist\")\ntest_dataset(\"notmnist\")\ntest_dataset(\"splitcifar100_0\")\ntest_dataset(\"splitcifar100_1\")\ntest_dataset(\"splitcifar100_19\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T05:17:45.912996Z","iopub.execute_input":"2026-02-05T05:17:45.913867Z","iopub.status.idle":"2026-02-05T05:18:57.412359Z","shell.execute_reply.started":"2026-02-05T05:17:45.913826Z","shell.execute_reply":"2026-02-05T05:18:57.411222Z"}},"outputs":[{"name":"stdout","text":"/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `EOF')\n\n==================================================\nTesting dataset: cifar10\n==================================================\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170M/170M [00:06<00:00, 28.2MB/s] \n","output_type":"stream"},{"name":"stdout","text":"ALDataset created ✓\nNumber of classes: 10\nTrain size: 50000\nVal size: 5000\nTest size: 5000\nSingle image shape: torch.Size([3, 32, 32])\nSingle label shape: torch.Size([10])\nBatch image shape: torch.Size([8, 3, 32, 32])\nBatch label shape: torch.Size([8, 10])\ncifar10 ✅ DATASET + DATALOADER WORKING\n\n==================================================\nTesting dataset: cifar100\n==================================================\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 169M/169M [00:08<00:00, 18.9MB/s] \n","output_type":"stream"},{"name":"stdout","text":"ALDataset created ✓\nNumber of classes: 100\nTrain size: 50000\nVal size: 5000\nTest size: 5000\nSingle image shape: torch.Size([3, 32, 32])\nSingle label shape: torch.Size([100])\nBatch image shape: torch.Size([8, 3, 32, 32])\nBatch label shape: torch.Size([8, 100])\ncifar100 ✅ DATASET + DATALOADER WORKING\n\n==================================================\nTesting dataset: tinyimagenet\n==================================================\nDownloading TinyImageNet...\nExtracting TinyImageNet...\nFixing train folder structure...\nFixing val folder structure...\nTinyImageNet ready at: ../data/tiny-imagenet-200\nALDataset created ✓\nNumber of classes: 200\nTrain size: 100000\nVal size: 10000\nTest size: 10000\nSingle image shape: torch.Size([3, 64, 64])\nSingle label shape: torch.Size([200])\nBatch image shape: torch.Size([8, 3, 64, 64])\nBatch label shape: torch.Size([8, 200])\ntinyimagenet ✅ DATASET + DATALOADER WORKING\n\n==================================================\nTesting dataset: cub200\n==================================================\nALDataset created ✓\nNumber of classes: 200\nTrain size: 5994\nVal size: 5794\nTest size: 5794\nSingle image shape: torch.Size([3, 224, 224])\nSingle label shape: torch.Size([200])\nBatch image shape: torch.Size([8, 3, 224, 224])\nBatch label shape: torch.Size([8, 200])\ncub200 ✅ DATASET + DATALOADER WORKING\n\n==================================================\nTesting dataset: fashionmnist\n==================================================\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 26.4M/26.4M [00:00<00:00, 113MB/s]\n100%|██████████| 29.5k/29.5k [00:00<00:00, 3.94MB/s]\n100%|██████████| 4.42M/4.42M [00:00<00:00, 57.7MB/s]\n100%|██████████| 5.15k/5.15k [00:00<00:00, 7.25MB/s]\n","output_type":"stream"},{"name":"stdout","text":"ALDataset created ✓\nNumber of classes: 10\nTrain size: 60000\nVal size: 10000\nTest size: 10000\nSingle image shape: torch.Size([1, 28, 28])\nSingle label shape: torch.Size([10])\nBatch image shape: torch.Size([8, 1, 28, 28])\nBatch label shape: torch.Size([8, 10])\nfashionmnist ✅ DATASET + DATALOADER WORKING\n\n==================================================\nTesting dataset: notmnist\n==================================================\nnotmnist ❌ FAILED\nReason: Couldn't find any class folder in ../data/notmnist.\n\n==================================================\nTesting dataset: splitcifar100_0\n==================================================\nALDataset created ✓\nNumber of classes: 5\nTrain size: 2500\nVal size: 500\nTest size: 500\nSingle image shape: torch.Size([3, 32, 32])\nSingle label shape: torch.Size([5])\nBatch image shape: torch.Size([8, 3, 32, 32])\nBatch label shape: torch.Size([8, 5])\nsplitcifar100_0 ✅ DATASET + DATALOADER WORKING\n\n==================================================\nTesting dataset: splitcifar100_1\n==================================================\nALDataset created ✓\nNumber of classes: 5\nTrain size: 2500\nVal size: 500\nTest size: 500\nSingle image shape: torch.Size([3, 32, 32])\nSingle label shape: torch.Size([5])\nBatch image shape: torch.Size([8, 3, 32, 32])\nBatch label shape: torch.Size([8, 5])\nsplitcifar100_1 ✅ DATASET + DATALOADER WORKING\n\n==================================================\nTesting dataset: splitcifar100_19\n==================================================\nALDataset created ✓\nNumber of classes: 5\nTrain size: 2500\nVal size: 500\nTest size: 500\nSingle image shape: torch.Size([3, 32, 32])\nSingle label shape: torch.Size([5])\nBatch image shape: torch.Size([8, 3, 32, 32])\nBatch label shape: torch.Size([8, 5])\nsplitcifar100_19 ✅ DATASET + DATALOADER WORKING\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# from LabelBench.dataset.datasets import get_dataset\n# from torch.utils.data import DataLoader\n\n# dataset = get_dataset(\"notmnist\", \"../data\")\n\n# print(\"ALDataset created ✓\")\n# print(\"Number of classes:\", dataset.get_num_classes())\n\n# train_ds = dataset.train_dataset\n# x, y = train_ds[0]\n# print(\"Single image shape:\", x.shape)\n# print(\"Single label shape:\", y.shape)\n\n# bx, by = next(iter(DataLoader(train_ds, batch_size=8)))\n# print(\"Batch image shape:\", bx.shape)\n# print(\"Batch label shape:\", by.shape)\n\n# print(\"notmnist ✅ DATASET + DATALOADER WORKING\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T05:18:57.413873Z","iopub.execute_input":"2026-02-05T05:18:57.414546Z","iopub.status.idle":"2026-02-05T05:18:57.420961Z","shell.execute_reply.started":"2026-02-05T05:18:57.414511Z","shell.execute_reply":"2026-02-05T05:18:57.419708Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# from LabelBench.dataset.datasets import get_dataset\n# from torch.utils.data import DataLoader\n\n# ds = get_dataset(\"fashionmnist\", \"./data\")\n\n# print(\"Classes:\", ds.get_num_classes())\n# x, y = ds.train_dataset[0]\n# print(x.shape, y.shape)\n\n# bx, by = next(iter(DataLoader(ds.train_dataset, batch_size=8)))\n# print(bx.shape, by.shape)\n\n# print(\"fashionmnist ✅ WORKING\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T05:18:57.422209Z","iopub.execute_input":"2026-02-05T05:18:57.422503Z","iopub.status.idle":"2026-02-05T05:18:57.448529Z","shell.execute_reply.started":"2026-02-05T05:18:57.422479Z","shell.execute_reply":"2026-02-05T05:18:57.447291Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# from LabelBench.dataset.datasets import get_dataset\n# from torch.utils.data import DataLoader\n\n# dataset = get_dataset(\"cub200\", \"../data\")\n# train_ds = dataset.train_dataset\n\n# print(\"Train length:\", len(train_ds))\n# x, y = train_ds[0]\n# print(\"Single image:\", x.shape)\n# print(\"Single label:\", y.shape)\n\n# bx, by = next(iter(DataLoader(train_ds, batch_size=8)))\n# print(\"Batch images:\", bx.shape)\n# print(\"Batch labels:\", by.shape)\n\n# print(\"✅ CUB200 DATASET + DATALOADER WORKING\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T05:18:57.449887Z","iopub.execute_input":"2026-02-05T05:18:57.450207Z","iopub.status.idle":"2026-02-05T05:18:57.471227Z","shell.execute_reply.started":"2026-02-05T05:18:57.450169Z","shell.execute_reply":"2026-02-05T05:18:57.469989Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# !python - << 'EOF'\n# from LabelBench.dataset.datasets import get_dataset\n# from torch.utils.data import DataLoader\n\n# dataset = get_dataset(\"tinyimagenet\", \"./data\")\n# train_ds = dataset.train_dataset\n\n# print(\"Length:\", len(train_ds))\n\n# x, y = train_ds[0]\n# print(\"Single image:\", x.shape)\n# print(\"Single label:\", y.shape)\n\n# bx, by = next(iter(DataLoader(train_ds, batch_size=8)))\n# print(\"Batch images:\", bx.shape)\n# print(\"Batch labels:\", by.shape)\n\n# print(\"✅ TinyImageNet COMPLETELY FIXED\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T05:18:57.472633Z","iopub.execute_input":"2026-02-05T05:18:57.473118Z","iopub.status.idle":"2026-02-05T05:18:57.494822Z","shell.execute_reply.started":"2026-02-05T05:18:57.473062Z","shell.execute_reply":"2026-02-05T05:18:57.493553Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# from LabelBench.dataset.datasets import get_dataset\n# from torch.utils.data import DataLoader\n\n# dataset = get_dataset(\"splitcifar10_0\", \"./data\")\n\n# print(\"ALDataset created ✓\")\n# print(\"Number of classes:\", dataset.get_num_classes())\n# train_ds = dataset.train_dataset\n# x, y = train_ds[0]\n# print(\"Single image:\", x.shape)\n# print(\"Single label:\", y.shape)\n\n# bx, by = next(iter(DataLoader(train_ds, batch_size=8)))\n# print(\"Batch images:\", bx.shape)\n# print(\"Batch labels:\", by.shape)\n\n# print(\"✅ SPLIT CIFAR-10 WORKING\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T05:18:57.496315Z","iopub.execute_input":"2026-02-05T05:18:57.496772Z","iopub.status.idle":"2026-02-05T05:18:57.516646Z","shell.execute_reply.started":"2026-02-05T05:18:57.496716Z","shell.execute_reply":"2026-02-05T05:18:57.515411Z"}},"outputs":[],"execution_count":19}]}